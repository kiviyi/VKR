{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1zbKJq4jyJNl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zbKJq4jyJNl",
        "outputId": "3ce4098c-037b-42bd-e35c-d1690051b63c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad57d27",
      "metadata": {
        "id": "8ad57d27"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import time\n",
        "import optuna\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f769643",
      "metadata": {
        "id": "1f769643"
      },
      "source": [
        "Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a5c99f",
      "metadata": {
        "id": "f0a5c99f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('daily_accidents.csv', parse_dates=['CRASH DATE'])\n",
        "\n",
        "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
        "\n",
        "df = df.groupby('CRASH DATE').agg({'ACCIDENT_COUNT': 'sum', 'TOTAL_INJURIES': 'sum'}).reset_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb98c8c4",
      "metadata": {
        "id": "bb98c8c4"
      },
      "source": [
        "Преобразованиее данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd81d029",
      "metadata": {
        "id": "fd81d029"
      },
      "outputs": [],
      "source": [
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "df['ACCIDENT_COUNT'] = scaler.fit_transform(df[['ACCIDENT_COUNT']])\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data[i:i+seq_length]\n",
        "        sequences.append(seq)\n",
        "    return np.array(sequences)\n",
        "\n",
        "sequence_length = 60\n",
        "accident_data = df['ACCIDENT_COUNT'].values\n",
        "\n",
        "sequences = create_sequences(accident_data, sequence_length)\n",
        "\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "X = np.expand_dims(X, axis=2)\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "test_data = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45961066",
      "metadata": {
        "id": "45961066"
      },
      "source": [
        "Модель Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04af001e",
      "metadata": {
        "id": "04af001e"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99df4380",
      "metadata": {
        "id": "99df4380"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_layers, output_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)     \n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        out = x[:, -1, :]\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ef5c0e2",
      "metadata": {},
      "source": [
        "Функция подбора гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J771kqzfypFC",
      "metadata": {
        "id": "J771kqzfypFC"
      },
      "outputs": [],
      "source": [
        "def objective_transformer(trial):\n",
        "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
        "    nhead_options = [h for h in [2, 4, 8] if d_model % h == 0]\n",
        "    if not nhead_options:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    nhead = trial.suggest_categorical(\"nhead\", nhead_options)\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        input_size=1,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        output_size=1,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(10):\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            val_loss += criterion(output, y_batch).item()\n",
        "\n",
        "    return val_loss / len(test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86a2f291",
      "metadata": {},
      "source": [
        "Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1WUmaSOyp-G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1WUmaSOyp-G",
        "outputId": "2721f858-68ee-4e02-afdd-db5ecb1d80b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 00:10:22,616] A new study created in memory with name: no-name-061433d2-39cc-4844-9f35-20480806a0e3\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "[I 2025-05-06 00:17:37,422] Trial 0 finished with value: 0.04047934152185917 and parameters: {'d_model': 64, 'nhead': 2, 'num_layers': 2, 'dropout': 0.2077406100713721, 'lr': 0.001900601801683295}. Best is trial 0 with value: 0.04047934152185917.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "[I 2025-05-06 00:28:49,284] Trial 1 finished with value: 0.038001079112291336 and parameters: {'d_model': 32, 'nhead': 2, 'num_layers': 4, 'dropout': 0.27651140000550534, 'lr': 0.0018996801360388615}. Best is trial 1 with value: 0.038001079112291336.\n",
            "[I 2025-05-06 00:39:10,208] Trial 2 finished with value: 0.0032840032363310456 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 3, 'dropout': 0.20894814099321957, 'lr': 0.003760298688563014}. Best is trial 2 with value: 0.0032840032363310456.\n",
            "[I 2025-05-06 00:48:33,504] Trial 3 finished with value: 0.0009181353379972279 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 2, 'dropout': 0.2784575878603218, 'lr': 0.0003996256627571321}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 00:58:44,708] Trial 4 finished with value: 0.0009681275114417076 and parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 2, 'dropout': 0.4758771359543871, 'lr': 0.003318998306691452}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 01:12:56,856] Trial 5 finished with value: 0.001363039598800242 and parameters: {'d_model': 64, 'nhead': 2, 'num_layers': 4, 'dropout': 0.14457710742175342, 'lr': 0.00023118512491396184}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 01:21:33,698] Trial 6 finished with value: 0.010573829989880323 and parameters: {'d_model': 32, 'nhead': 2, 'num_layers': 3, 'dropout': 0.4699970825089822, 'lr': 0.002327855884574952}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 01:30:23,464] Trial 7 finished with value: 0.004878570092841983 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 2, 'dropout': 0.38932970397879785, 'lr': 0.00018782063450303562}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 01:33:45,352] Trial 8 finished with value: 0.009975817054510117 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 1, 'dropout': 0.40316446354255653, 'lr': 0.0034593102047084188}. Best is trial 3 with value: 0.0009181353379972279.\n",
            "[I 2025-05-06 01:45:18,736] Trial 9 finished with value: 0.0009012253431137651 and parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'dropout': 0.20985223568872088, 'lr': 0.00021786056525951273}. Best is trial 9 with value: 0.0009012253431137651.\n",
            "[I 2025-05-06 02:04:50,268] Trial 10 finished with value: 0.0028731415513902903 and parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 4, 'dropout': 0.14160833411419954, 'lr': 0.0005769064987239499}. Best is trial 9 with value: 0.0009012253431137651.\n",
            "[I 2025-05-06 02:08:48,364] Trial 11 finished with value: 0.0018560640746727586 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 1, 'dropout': 0.2830202528927833, 'lr': 0.00047895482100159773}. Best is trial 9 with value: 0.0009012253431137651.\n",
            "[I 2025-05-06 02:22:29,067] Trial 12 finished with value: 0.0008045835129451007 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 3, 'dropout': 0.2228463047859486, 'lr': 0.00010334744618188217}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 02:35:28,945] Trial 13 finished with value: 0.0011045863502658904 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.21710889977674724, 'lr': 0.00010441431978562414}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 02:47:41,384] Trial 14 finished with value: 0.0009795408113859594 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'dropout': 0.1029597848052634, 'lr': 0.00010065564542707431}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 03:00:33,774] Trial 15 finished with value: 0.005346469348296523 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.23122389535394655, 'lr': 0.008214098702197838}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 03:21:10,747] Trial 16 finished with value: 0.008214018307626247 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'dropout': 0.33487182998833276, 'lr': 0.0002148131518628276}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 03:31:04,294] Trial 17 finished with value: 0.000989079533610493 and parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 3, 'dropout': 0.32458085901723566, 'lr': 0.00096473351817423}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 03:42:43,581] Trial 18 finished with value: 0.0009382861317135394 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'dropout': 0.16821603441572638, 'lr': 0.00014949421567832518}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 03:54:55,515] Trial 19 finished with value: 0.0008287208038382232 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.2390235237833146, 'lr': 0.0003484317834116572}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 04:08:39,531] Trial 20 finished with value: 0.0016212163027375937 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 3, 'dropout': 0.3684730755298875, 'lr': 0.00032766478780722367}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 04:21:32,792] Trial 21 finished with value: 0.0020118390675634146 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.24067067082464771, 'lr': 0.000778579179489711}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 04:34:32,140] Trial 22 finished with value: 0.0008876551582943648 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.17696744894677607, 'lr': 0.00029363444261427723}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 04:47:18,217] Trial 23 finished with value: 0.00227325945161283 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.17078605179478606, 'lr': 0.0003013152330005205}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 04:55:35,074] Trial 24 finished with value: 0.0013850410468876362 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 2, 'dropout': 0.25665069254833733, 'lr': 0.0006138774138384421}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 05:08:24,271] Trial 25 finished with value: 0.0009308839507866651 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.1838664486300896, 'lr': 0.00014035447095677199}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 05:16:35,484] Trial 26 finished with value: 0.005667113233357668 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 2, 'dropout': 0.10371735122541431, 'lr': 0.0012969846909341252}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 05:29:12,363] Trial 27 finished with value: 0.0009181398781947792 and parameters: {'d_model': 96, 'nhead': 4, 'num_layers': 3, 'dropout': 0.31159189935147624, 'lr': 0.00033371763157854264}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 05:41:32,134] Trial 28 finished with value: 0.001732854696456343 and parameters: {'d_model': 96, 'nhead': 2, 'num_layers': 3, 'dropout': 0.1331844651220621, 'lr': 0.00014259536624081429}. Best is trial 12 with value: 0.0008045835129451007.\n",
            "[I 2025-05-06 05:49:05,112] Trial 29 finished with value: 0.0018425468588247895 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 2, 'dropout': 0.2510594381202531, 'lr': 0.00026625338472204116}. Best is trial 12 with value: 0.0008045835129451007.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'d_model': 96, 'nhead': 8, 'num_layers': 3, 'dropout': 0.2228463047859486, 'lr': 0.00010334744618188217}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_transformer, n_trials=30)\n",
        "print(\"Best hyperparameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1d2e9fd",
      "metadata": {
        "id": "c1d2e9fd"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "e4bf6e5e",
      "metadata": {
        "id": "e4bf6e5e"
      },
      "outputs": [],
      "source": [
        "input_size = 1\n",
        "d_model = 96\n",
        "nhead = 8\n",
        "num_layers = 3\n",
        "output_size = 1\n",
        "dropout = 0.2228463047859486\n",
        "num_epochs = 400"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eb0940",
      "metadata": {
        "id": "11eb0940"
      },
      "source": [
        "Инициализация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c0723d01",
      "metadata": {
        "id": "c0723d01"
      },
      "outputs": [],
      "source": [
        "model = TransformerModel(input_size=input_size, d_model=d_model, nhead=nhead, num_layers=num_layers, output_size=output_size, dropout=dropout)\n",
        "model = model.to(device)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a32aa700",
      "metadata": {
        "id": "a32aa700"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.00010334744618188217)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d710068",
      "metadata": {
        "id": "7d710068"
      },
      "source": [
        "Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "oAcCzh-J_szZ",
      "metadata": {
        "id": "oAcCzh-J_szZ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "best_model_state = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d483723",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d483723",
        "outputId": "2c5a7256-8f3d-4d25-ce21-0a903bdf74e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/400], Loss: 0.0204, Val Loss: 0.0008\n",
            "Epoch [20/400], Loss: 0.0150, Val Loss: 0.0009\n",
            "Epoch [30/400], Loss: 0.0117, Val Loss: 0.0008\n",
            "Epoch [40/400], Loss: 0.0132, Val Loss: 0.0013\n",
            "Epoch [50/400], Loss: 0.0090, Val Loss: 0.0021\n",
            "Early stopping at epoch 53\n",
            "Training time: 4461.16 seconds\n"
          ]
        }
      ],
      "source": [
        "patience = 40\n",
        "best_val_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            val_loss += criterion(output, y_batch).item()\n",
        "    val_loss /= len(test_loader)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a74fdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eee12177",
      "metadata": {
        "id": "eee12177"
      },
      "source": [
        "Прогнозирование и возвращение оригинального масштаба"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94ff3b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94ff3b8",
        "outputId": "6f805a15-e9d5-4952-c517-81b442ec12cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer RMSE: 30.075539661617047, MAE: 23.628387451171875, R²: 0.26948028802871704, Correlation: 0.5294751021921705\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "y_test_original = y_test.cpu().numpy()\n",
        "\n",
        "y_pred = scaler.inverse_transform(y_pred)\n",
        "y_test_original = scaler.inverse_transform(y_test_original)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred))\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "correlation = np.corrcoef(y_test_original.flatten(), y_pred.flatten())[0, 1]\n",
        "\n",
        "print(f\"Transformer RMSE: {rmse}, MAE: {mae}, R²: {r2}, Correlation: {correlation}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
