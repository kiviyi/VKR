{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i7KF4fWfyvzQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7KF4fWfyvzQ",
        "outputId": "2e134a4b-b942-481f-efe9-1ed5a3652e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna pytorch-lightning pytorch-forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e5593e9a",
      "metadata": {
        "id": "e5593e9a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f60723",
      "metadata": {
        "id": "77f60723"
      },
      "source": [
        "Загрузка данных и создание датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "38ff29b5",
      "metadata": {
        "id": "38ff29b5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('daily_accidents.csv', parse_dates=['CRASH DATE'])\n",
        "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
        "df.set_index('CRASH DATE', inplace=True)\n",
        "\n",
        "df = df[['ACCIDENT_COUNT']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e5e00e8a",
      "metadata": {
        "id": "e5e00e8a"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "df_scaled = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "af77d1de",
      "metadata": {
        "id": "af77d1de"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "seq_length = 30\n",
        "\n",
        "for i in range(len(df_scaled) - seq_length):\n",
        "    X.append(df_scaled[i:i + seq_length])\n",
        "    y.append(df_scaled[i + seq_length])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b10df4d5",
      "metadata": {
        "id": "b10df4d5"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307d9097",
      "metadata": {
        "id": "307d9097"
      },
      "source": [
        "Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "97da4f8e",
      "metadata": {
        "id": "97da4f8e"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class LSTransformerFusion(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_heads, output_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(d_model=hidden_size, dropout=dropout)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_size,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_size * 2,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
        "\n",
        "        self.fusion_fc = nn.Linear(2 * hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        transformer_input = self.positional_encoding(x)\n",
        "        transformer_out = self.transformer_encoder(transformer_input)\n",
        "\n",
        "        lstm_last = lstm_out[:, -1, :]\n",
        "        transformer_last = transformer_out[:, -1, :]\n",
        "        fused = torch.cat([lstm_last, transformer_last], dim=-1)\n",
        "\n",
        "        return self.fusion_fc(fused)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e20db207",
      "metadata": {
        "id": "e20db207"
      },
      "source": [
        "Функция подбора гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QWKps-6_zFbE",
      "metadata": {
        "id": "QWKps-6_zFbE"
      },
      "outputs": [],
      "source": [
        "def objective_lstransformer(trial):\n",
        "    num_heads = trial.suggest_categorical(\"num_heads\", [2, 4, 8])\n",
        "\n",
        "    hidden_size_options = [hs for hs in range(32, 257, 8) if hs % num_heads == 0]\n",
        "    hidden_size = trial.suggest_categorical(\"hidden_size\", hidden_size_options)\n",
        "\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = LSTransformerFusion(\n",
        "        input_size=X_train.shape[2],\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_heads=num_heads,\n",
        "        output_size=1\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs, labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs, labels\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    return test_loss / len(test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fdf2b36",
      "metadata": {
        "id": "9fdf2b36"
      },
      "source": [
        "Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "QF5S0vUSzUgm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QF5S0vUSzUgm",
        "outputId": "897bc9cd-754e-4338-b9b6-8578c3e5e00c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-13 18:31:31,634] A new study created in memory with name: no-name-c46b6be4-e73e-436c-a334-0da56166f6bc\n",
            "[I 2025-05-13 18:34:35,203] Trial 0 finished with value: 0.003140741609968245 and parameters: {'num_heads': 4, 'hidden_size': 128, 'num_layers': 2, 'lr': 0.0003433234531632159}. Best is trial 0 with value: 0.003140741609968245.\n",
            "[I 2025-05-13 18:35:57,013] Trial 1 finished with value: 0.0030078409472480416 and parameters: {'num_heads': 8, 'hidden_size': 56, 'num_layers': 3, 'lr': 0.0021474865587272404}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 18:36:33,983] Trial 2 finished with value: 0.0031521099153906107 and parameters: {'num_heads': 2, 'hidden_size': 32, 'num_layers': 3, 'lr': 0.0018211195136755044}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 18:42:59,505] Trial 3 finished with value: 0.0031176169868558645 and parameters: {'num_heads': 2, 'hidden_size': 224, 'num_layers': 2, 'lr': 0.0016106530500180599}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 18:47:09,855] Trial 4 finished with value: 0.003389377030543983 and parameters: {'num_heads': 8, 'hidden_size': 160, 'num_layers': 2, 'lr': 0.00010664807065935639}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 18:50:10,669] Trial 5 finished with value: 0.003368159639649093 and parameters: {'num_heads': 8, 'hidden_size': 128, 'num_layers': 2, 'lr': 0.009749738468395384}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 18:54:37,107] Trial 6 finished with value: 0.004252020036801696 and parameters: {'num_heads': 4, 'hidden_size': 232, 'num_layers': 1, 'lr': 0.00047135558701614036}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:02:49,561] Trial 7 finished with value: 0.00333868560846895 and parameters: {'num_heads': 2, 'hidden_size': 256, 'num_layers': 2, 'lr': 0.0004717354569203284}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:07:23,305] Trial 8 finished with value: 0.0030334716429933906 and parameters: {'num_heads': 4, 'hidden_size': 240, 'num_layers': 1, 'lr': 0.0019470597759039337}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:10:26,649] Trial 9 finished with value: 0.005005064886063337 and parameters: {'num_heads': 4, 'hidden_size': 184, 'num_layers': 1, 'lr': 0.00012910317039133671}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:11:46,997] Trial 10 finished with value: 0.003343441989272833 and parameters: {'num_heads': 8, 'hidden_size': 56, 'num_layers': 3, 'lr': 0.005286189913395171}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:16:23,567] Trial 11 finished with value: 0.0031734685180708766 and parameters: {'num_heads': 4, 'hidden_size': 240, 'num_layers': 1, 'lr': 0.002777999686682572}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:26:28,908] Trial 12 finished with value: 0.0038484371034428477 and parameters: {'num_heads': 8, 'hidden_size': 240, 'num_layers': 3, 'lr': 0.0009979722898402173}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:28:18,033] Trial 13 finished with value: 0.003279017983004451 and parameters: {'num_heads': 8, 'hidden_size': 120, 'num_layers': 1, 'lr': 0.003008482013203327}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:29:30,036] Trial 14 finished with value: 0.0030923509038984776 and parameters: {'num_heads': 4, 'hidden_size': 56, 'num_layers': 3, 'lr': 0.0010692614191402953}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:30:09,281] Trial 15 finished with value: 0.003016468370333314 and parameters: {'num_heads': 8, 'hidden_size': 48, 'num_layers': 1, 'lr': 0.004256772205051522}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:36:22,726] Trial 16 finished with value: 0.003156725550070405 and parameters: {'num_heads': 8, 'hidden_size': 176, 'num_layers': 3, 'lr': 0.005320086633563891}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:37:13,304] Trial 17 finished with value: 0.003476892365142703 and parameters: {'num_heads': 8, 'hidden_size': 48, 'num_layers': 2, 'lr': 0.009608077657691606}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:38:17,969] Trial 18 finished with value: 0.0030281224753707647 and parameters: {'num_heads': 8, 'hidden_size': 48, 'num_layers': 3, 'lr': 0.0047508791383090365}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:41:57,205] Trial 19 finished with value: 0.00310543947853148 and parameters: {'num_heads': 8, 'hidden_size': 200, 'num_layers': 1, 'lr': 0.0036972882501247186}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:43:11,807] Trial 20 finished with value: 0.0031045335344970226 and parameters: {'num_heads': 8, 'hidden_size': 64, 'num_layers': 2, 'lr': 0.001201991000032161}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:44:16,633] Trial 21 finished with value: 0.003321547294035554 and parameters: {'num_heads': 8, 'hidden_size': 48, 'num_layers': 3, 'lr': 0.005129596330138094}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 19:56:51,372] Trial 22 finished with value: 0.004760959651321173 and parameters: {'num_heads': 8, 'hidden_size': 248, 'num_layers': 3, 'lr': 0.0069084529824592475}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:05:25,426] Trial 23 finished with value: 0.003681370406411588 and parameters: {'num_heads': 8, 'hidden_size': 216, 'num_layers': 3, 'lr': 0.003419155496258362}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:10:01,262] Trial 24 finished with value: 0.0030243793735280633 and parameters: {'num_heads': 8, 'hidden_size': 144, 'num_layers': 3, 'lr': 0.002394333743429013}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:16:52,314] Trial 25 finished with value: 0.0035963167902082205 and parameters: {'num_heads': 2, 'hidden_size': 192, 'num_layers': 3, 'lr': 0.0023383238450319075}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:20:18,290] Trial 26 finished with value: 0.0031856748973950744 and parameters: {'num_heads': 8, 'hidden_size': 144, 'num_layers': 2, 'lr': 0.0007524896443324461}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:26:15,612] Trial 27 finished with value: 0.003300732932984829 and parameters: {'num_heads': 8, 'hidden_size': 208, 'num_layers': 2, 'lr': 0.0015731610115250695}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:29:13,766] Trial 28 finished with value: 0.003125901217572391 and parameters: {'num_heads': 8, 'hidden_size': 104, 'num_layers': 3, 'lr': 0.0006898770123674823}. Best is trial 1 with value: 0.0030078409472480416.\n",
            "[I 2025-05-13 20:30:20,472] Trial 29 finished with value: 0.003219028702005744 and parameters: {'num_heads': 2, 'hidden_size': 88, 'num_layers': 1, 'lr': 0.004100140963442262}. Best is trial 1 with value: 0.0030078409472480416.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'num_heads': 8, 'hidden_size': 56, 'num_layers': 3, 'lr': 0.0021474865587272404}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_lstransformer, n_trials=30)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e0dc3d",
      "metadata": {
        "id": "85e0dc3d"
      },
      "source": [
        "Параметры модели и инициализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "85fffb8f",
      "metadata": {
        "id": "85fffb8f"
      },
      "outputs": [],
      "source": [
        "input_size = 1\n",
        "hidden_size = 56\n",
        "num_layers = 3\n",
        "num_heads = 8\n",
        "output_size = 1\n",
        "learning_rate = 0.0021474865587272404\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "cc5b2906",
      "metadata": {
        "id": "cc5b2906"
      },
      "outputs": [],
      "source": [
        "model = LSTransformerFusion(input_size, hidden_size, num_layers, num_heads, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6a4f667b",
      "metadata": {
        "id": "6a4f667b"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "dc3ae887",
      "metadata": {
        "id": "dc3ae887"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5165520",
      "metadata": {
        "id": "e5165520"
      },
      "source": [
        "Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "rf6nwNaRZW7g",
      "metadata": {
        "id": "rf6nwNaRZW7g"
      },
      "outputs": [],
      "source": [
        "epochs = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "8e3dfe9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e3dfe9e",
        "outputId": "277c4bc6-9acf-4347-a1a3-c47a21b88f74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/150, Loss: 0.0287\n",
            "Epoch 20/150, Loss: 0.0276\n",
            "Epoch 30/150, Loss: 0.0208\n",
            "Epoch 40/150, Loss: 0.0252\n",
            "Epoch 50/150, Loss: 0.0190\n",
            "Epoch 60/150, Loss: 0.0199\n",
            "Epoch 70/150, Loss: 0.0201\n",
            "Epoch 80/150, Loss: 0.0198\n",
            "Epoch 90/150, Loss: 0.0206\n",
            "Epoch 100/150, Loss: 0.0200\n",
            "Epoch 110/150, Loss: 0.0194\n",
            "Epoch 120/150, Loss: 0.0201\n",
            "Epoch 130/150, Loss: 0.0194\n",
            "Epoch 140/150, Loss: 0.0199\n",
            "Epoch 150/150, Loss: 0.0192\n",
            "Training completed in 550.93 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "train_loss = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for i in range(0, X_train.shape[0], batch_size):\n",
        "        X_batch = X_train[i:i + batch_size]\n",
        "        y_batch = y_train[i:i + batch_size]\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(X_batch)\n",
        "\n",
        "        if y_batch.ndim == 1:\n",
        "            y_batch = y_batch.unsqueeze(1)\n",
        "\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        batch_count += 1\n",
        "\n",
        "    avg_loss = running_loss / batch_count\n",
        "    train_loss.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training completed in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a92da3e3",
      "metadata": {
        "id": "a92da3e3"
      },
      "source": [
        "Предсказание и метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "b97d908f",
      "metadata": {
        "id": "b97d908f"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train).detach().numpy()\n",
        "    y_pred_test = model(X_test).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d8f67efe",
      "metadata": {
        "id": "d8f67efe"
      },
      "outputs": [],
      "source": [
        "y_pred_train = scaler.inverse_transform(y_pred_train)\n",
        "y_pred_test = scaler.inverse_transform(y_pred_test)\n",
        "y_train = scaler.inverse_transform(y_train.numpy())\n",
        "y_test = scaler.inverse_transform(y_test.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "09c34901",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09c34901",
        "outputId": "910c71d5-f15c-4e86-9005-52543bdc97fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train RMSE: 69.9796, MAE: 49.9274, R²: 0.8118, Correlation: 0.9079\n",
            "Test RMSE: 30.1629, MAE: 23.5648, R²: 0.2705, Correlation: 0.5634\n"
          ]
        }
      ],
      "source": [
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "correlation_train = np.corrcoef(y_train.flatten(), y_pred_train.flatten())[0, 1]\n",
        "correlation_test = np.corrcoef(y_test.flatten(), y_pred_test.flatten())[0, 1]\n",
        "\n",
        "print(f'Train RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}, Correlation: {correlation_train:.4f}')\n",
        "print(f'Test RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}, Correlation: {correlation_test:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
