{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kGUbZ8xkUXGz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGUbZ8xkUXGz",
        "outputId": "be9290a5-a27c-4ae7-dc3b-4f52e296ed18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5593e9a",
      "metadata": {
        "id": "e5593e9a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "037d5f46",
      "metadata": {},
      "source": [
        "Загрузка данных и создание датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ff29b5",
      "metadata": {
        "id": "38ff29b5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('daily_accidents_hol_dw_week.csv', parse_dates=['CRASH DATE'])\n",
        "df['CRASH DATE'] = pd.to_datetime(df['CRASH DATE'])\n",
        "df.set_index('CRASH DATE', inplace=True)\n",
        "\n",
        "features = ['CRASH_COUNT', 'is_weekend', 'month', 'is_holiday']\n",
        "df = df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5e00e8a",
      "metadata": {
        "id": "e5e00e8a"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "df_scaled = scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af77d1de",
      "metadata": {
        "id": "af77d1de"
      },
      "outputs": [],
      "source": [
        "seq_length = 30\n",
        "X, y = [], []\n",
        "\n",
        "for i in range(len(df_scaled) - seq_length):\n",
        "    seq_x = df_scaled[i:i + seq_length]\n",
        "    target_y = df_scaled[i + seq_length][0]\n",
        "    X.append(seq_x)\n",
        "    y.append(target_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10df4d5",
      "metadata": {
        "id": "b10df4d5"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y).reshape(-1, 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91a7dd87",
      "metadata": {},
      "source": [
        "Модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97da4f8e",
      "metadata": {
        "id": "97da4f8e"
      },
      "outputs": [],
      "source": [
        "class LSTransformer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_heads, output_size):\n",
        "        super(LSTransformer, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        transformer_out = self.transformer_encoder(lstm_out)\n",
        "        output = self.fc(transformer_out[:, -1, :])\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63eb8d7",
      "metadata": {},
      "source": [
        "Функция подбора гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "URy2MkqIUQuK",
      "metadata": {
        "id": "URy2MkqIUQuK"
      },
      "outputs": [],
      "source": [
        "def objective_lstransformer(trial):\n",
        "    num_heads = trial.suggest_categorical(\"num_heads\", [2, 4, 8])\n",
        "\n",
        "    hidden_size_options = [hs for hs in range(32, 257, 8) if hs % num_heads == 0]\n",
        "    hidden_size = trial.suggest_categorical(\"hidden_size\", hidden_size_options)\n",
        "\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = LSTransformer(\n",
        "        input_size=X_train.shape[2],\n",
        "        hidden_size=hidden_size,\n",
        "        num_layers=num_layers,\n",
        "        num_heads=num_heads,\n",
        "        output_size=1\n",
        "    )\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "    return test_loss / len(test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5be094",
      "metadata": {},
      "source": [
        "Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "irximMX_USDH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irximMX_USDH",
        "outputId": "50b908f6-a2a2-4fee-f2e1-60764fda6bb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-05 14:10:11,860] A new study created in memory with name: no-name-1b6646c9-fcbb-42bb-8c00-448c0d65ece1\n",
            "[I 2025-05-05 14:24:00,911] Trial 0 finished with value: 0.2215094342827797 and parameters: {'num_heads': 2, 'hidden_size': 56, 'num_layers': 3, 'lr': 0.005898766007835046}. Best is trial 0 with value: 0.2215094342827797.\n",
            "[I 2025-05-05 14:59:06,092] Trial 1 finished with value: 0.23898731172084808 and parameters: {'num_heads': 4, 'hidden_size': 200, 'num_layers': 3, 'lr': 0.0099181390554248}. Best is trial 0 with value: 0.2215094342827797.\n",
            "[I 2025-05-05 15:08:52,897] Trial 2 finished with value: 0.005596517585217953 and parameters: {'num_heads': 2, 'hidden_size': 224, 'num_layers': 1, 'lr': 0.00031408312450368833}. Best is trial 2 with value: 0.005596517585217953.\n",
            "[I 2025-05-05 15:17:13,044] Trial 3 finished with value: 0.004917545476928353 and parameters: {'num_heads': 4, 'hidden_size': 136, 'num_layers': 1, 'lr': 0.0008851872046987849}. Best is trial 3 with value: 0.004917545476928353.\n",
            "[I 2025-05-05 15:27:00,424] Trial 4 finished with value: 0.005111153470352292 and parameters: {'num_heads': 2, 'hidden_size': 224, 'num_layers': 1, 'lr': 0.00014412854439161665}. Best is trial 3 with value: 0.004917545476928353.\n",
            "[I 2025-05-05 15:36:14,371] Trial 5 finished with value: 0.005035538924857974 and parameters: {'num_heads': 2, 'hidden_size': 208, 'num_layers': 1, 'lr': 0.000234280110985483}. Best is trial 3 with value: 0.004917545476928353.\n",
            "[I 2025-05-05 15:45:31,699] Trial 6 finished with value: 0.004256332525983453 and parameters: {'num_heads': 4, 'hidden_size': 168, 'num_layers': 1, 'lr': 0.00019592438267347}. Best is trial 6 with value: 0.004256332525983453.\n",
            "[I 2025-05-05 16:01:10,256] Trial 7 finished with value: 0.014271936379373074 and parameters: {'num_heads': 4, 'hidden_size': 40, 'num_layers': 3, 'lr': 0.0002673339364860881}. Best is trial 6 with value: 0.004256332525983453.\n",
            "[I 2025-05-05 16:08:42,020] Trial 8 finished with value: 0.008757657371461391 and parameters: {'num_heads': 8, 'hidden_size': 32, 'num_layers': 1, 'lr': 0.006310172254516771}. Best is trial 6 with value: 0.004256332525983453.\n",
            "[I 2025-05-05 16:20:43,622] Trial 9 finished with value: 0.2426532581448555 and parameters: {'num_heads': 2, 'hidden_size': 104, 'num_layers': 2, 'lr': 0.001475821836578838}. Best is trial 6 with value: 0.004256332525983453.\n",
            "[I 2025-05-05 16:43:35,598] Trial 10 finished with value: 0.021779191680252552 and parameters: {'num_heads': 8, 'hidden_size': 168, 'num_layers': 2, 'lr': 0.00010078861148657632}. Best is trial 6 with value: 0.004256332525983453.\n",
            "[I 2025-05-05 17:00:22,808] Trial 11 finished with value: 0.0038023203378543258 and parameters: {'num_heads': 4, 'hidden_size': 144, 'num_layers': 2, 'lr': 0.0008935522745619409}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 17:20:13,446] Trial 12 finished with value: 0.16272025555372238 and parameters: {'num_heads': 4, 'hidden_size': 192, 'num_layers': 2, 'lr': 0.0009078431974383427}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 17:31:59,156] Trial 13 finished with value: 0.004620260908268392 and parameters: {'num_heads': 4, 'hidden_size': 64, 'num_layers': 2, 'lr': 0.0018336574336016707}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 17:48:47,667] Trial 14 finished with value: 0.03892413713037968 and parameters: {'num_heads': 4, 'hidden_size': 144, 'num_layers': 2, 'lr': 0.0005497826702094519}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 18:07:16,663] Trial 15 finished with value: 0.24187857657670975 and parameters: {'num_heads': 4, 'hidden_size': 168, 'num_layers': 2, 'lr': 0.0021851480651317243}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 18:18:40,515] Trial 16 finished with value: 0.00609874096699059 and parameters: {'num_heads': 4, 'hidden_size': 232, 'num_layers': 1, 'lr': 0.00045727237306331315}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 18:44:04,288] Trial 17 finished with value: 0.22419659793376923 and parameters: {'num_heads': 8, 'hidden_size': 72, 'num_layers': 3, 'lr': 0.00323406249454636}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 18:52:35,430] Trial 18 finished with value: 0.004933968652039766 and parameters: {'num_heads': 4, 'hidden_size': 144, 'num_layers': 1, 'lr': 0.0005938228092909341}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 19:07:19,236] Trial 19 finished with value: 0.026664258912205696 and parameters: {'num_heads': 4, 'hidden_size': 112, 'num_layers': 2, 'lr': 0.00016964754607550245}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 19:35:44,374] Trial 20 finished with value: 0.04196917451918125 and parameters: {'num_heads': 8, 'hidden_size': 240, 'num_layers': 2, 'lr': 0.0004166862456240075}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 19:47:27,619] Trial 21 finished with value: 0.009037571493536234 and parameters: {'num_heads': 4, 'hidden_size': 64, 'num_layers': 2, 'lr': 0.0015913900926923373}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 20:01:00,407] Trial 22 finished with value: 0.20795754343271255 and parameters: {'num_heads': 4, 'hidden_size': 88, 'num_layers': 2, 'lr': 0.002969236839559296}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 20:33:49,264] Trial 23 finished with value: 0.20251372456550598 and parameters: {'num_heads': 4, 'hidden_size': 216, 'num_layers': 3, 'lr': 0.0012899493910307367}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 20:40:35,892] Trial 24 finished with value: 0.005099874222651124 and parameters: {'num_heads': 4, 'hidden_size': 96, 'num_layers': 1, 'lr': 0.000759341288253516}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 20:56:09,370] Trial 25 finished with value: 0.23958039283752441 and parameters: {'num_heads': 4, 'hidden_size': 128, 'num_layers': 2, 'lr': 0.002199998234594153}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 21:25:19,242] Trial 26 finished with value: 0.22607167065143585 and parameters: {'num_heads': 4, 'hidden_size': 184, 'num_layers': 3, 'lr': 0.004291768704654668}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 21:42:46,048] Trial 27 finished with value: 0.1937369406223297 and parameters: {'num_heads': 4, 'hidden_size': 152, 'num_layers': 2, 'lr': 0.0018670261653625743}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 21:57:01,280] Trial 28 finished with value: 0.003979050787165761 and parameters: {'num_heads': 8, 'hidden_size': 256, 'num_layers': 1, 'lr': 0.001310359285070908}. Best is trial 11 with value: 0.0038023203378543258.\n",
            "[I 2025-05-05 22:11:29,186] Trial 29 finished with value: 0.00413093576207757 and parameters: {'num_heads': 8, 'hidden_size': 256, 'num_layers': 1, 'lr': 0.001152808332473866}. Best is trial 11 with value: 0.0038023203378543258.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'num_heads': 4, 'hidden_size': 144, 'num_layers': 2, 'lr': 0.0008935522745619409}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_lstransformer, n_trials=30)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179bafcd",
      "metadata": {},
      "source": [
        "Параметры модели и инициализация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "85fffb8f",
      "metadata": {
        "id": "85fffb8f"
      },
      "outputs": [],
      "source": [
        "input_size = X_train.shape[2]\n",
        "hidden_size = 144\n",
        "num_layers = 2\n",
        "num_heads = 4\n",
        "output_size = 1\n",
        "learning_rate = 0.0008935522745619409\n",
        "epochs = 400\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cc5b2906",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc5b2906",
        "outputId": "d97ca6c3-9459-4a9c-a5bd-759351fdc4da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = LSTransformer(input_size, hidden_size, num_layers, num_heads, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4180ced6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4180ced6",
        "outputId": "46763d6e-09b1-46a9-a048-8dba48575074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3707, 30, 4])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6a4f667b",
      "metadata": {
        "id": "6a4f667b"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3ae887",
      "metadata": {
        "id": "dc3ae887"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00fc994b",
      "metadata": {},
      "source": [
        "Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8e3dfe9e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e3dfe9e",
        "outputId": "2b4cdbb9-667d-4857-eed7-6b5507490cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/400, Train Loss: 0.0174, Val Loss: 0.0040\n",
            "Early stopping at epoch 12\n",
            "Training completed in 463.02 seconds\n"
          ]
        }
      ],
      "source": [
        "patience = 10\n",
        "best_val_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "\n",
        "train_loss = []\n",
        "start_time = time.time()\n",
        "\n",
        "best_model_state = None  # чтобы сохранить лучшую модель\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i in range(0, X_train.shape[0], batch_size):\n",
        "        X_batch = X_train[i:i + batch_size]\n",
        "        y_batch = y_train[i:i + batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / (X_train.shape[0] // batch_size)\n",
        "    train_loss.append(avg_loss)\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_val, y_val in test_loader:\n",
        "            val_output = model(X_val)\n",
        "            val_loss += criterion(val_output, y_val).item()\n",
        "    val_loss /= len(test_loader)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stopping_counter = 0\n",
        "        best_model_state = model.state_dict()\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "# Восстановить лучшую модель\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bb8a3b",
      "metadata": {},
      "source": [
        "Предсказание и метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97d908f",
      "metadata": {
        "id": "b97d908f"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train).detach().numpy()\n",
        "    y_pred_test = model(X_test).detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f67efe",
      "metadata": {
        "id": "d8f67efe"
      },
      "outputs": [],
      "source": [
        "crash_count_index = features.index('CRASH_COUNT')\n",
        "y_pred_train_real = scaler.inverse_transform(\n",
        "    np.hstack([y_pred_train, np.zeros((len(y_pred_train), len(features) - 1))])\n",
        ")[:, crash_count_index]\n",
        "y_pred_test_real = scaler.inverse_transform(\n",
        "    np.hstack([y_pred_test, np.zeros((len(y_pred_test), len(features) - 1))])\n",
        ")[:, crash_count_index]\n",
        "y_train_real = scaler.inverse_transform(\n",
        "    np.hstack([y_train.numpy(), np.zeros((len(y_train), len(features) - 1))])\n",
        ")[:, crash_count_index]\n",
        "y_test_real = scaler.inverse_transform(\n",
        "    np.hstack([y_test.numpy(), np.zeros((len(y_test), len(features) - 1))])\n",
        ")[:, crash_count_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c34901",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09c34901",
        "outputId": "e51a39f2-3b87-4c53-e7c4-fa84f887a895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train RMSE: 80.7345, MAE: 61.5714, R²: 0.7496, Correlation: 0.8945\n",
            "Test  RMSE: 31.4903, MAE: 24.5075, R²: 0.2049, Correlation: 0.5167\n"
          ]
        }
      ],
      "source": [
        "def print_metrics(y_true, y_pred, prefix=\"\"):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    corr = np.corrcoef(y_true.flatten(), y_pred.flatten())[0, 1]\n",
        "    print(f'{prefix}RMSE: {rmse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}, Correlation: {corr:.4f}')\n",
        "\n",
        "print_metrics(y_train_real, y_pred_train_real, \"Train \")\n",
        "print_metrics(y_test_real, y_pred_test_real, \"Test  \")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
