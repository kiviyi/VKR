{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1zbKJq4jyJNl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zbKJq4jyJNl",
        "outputId": "7ebd145b-9cf9-4add-9312-e5fcbd395c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ad57d27",
      "metadata": {
        "id": "8ad57d27"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import time\n",
        "import optuna\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f769643",
      "metadata": {
        "id": "1f769643"
      },
      "source": [
        "Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a5c99f",
      "metadata": {
        "id": "f0a5c99f"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('daily_accidents_hol_dw_week.csv', parse_dates=['CRASH DATE'])\n",
        "df.set_index('CRASH DATE', inplace=True)\n",
        "df = df[['CRASH_COUNT', 'is_weekend', 'month', 'is_holiday']]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb98c8c4",
      "metadata": {
        "id": "bb98c8c4"
      },
      "source": [
        "Преобразованиее данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd81d029",
      "metadata": {
        "id": "fd81d029"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(df.values)\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        seq = data[i:i+seq_length]\n",
        "        target = data[i+seq_length][0]\n",
        "        sequences.append(seq)\n",
        "        targets.append(target)\n",
        "    return np.array(sequences), np.array(targets)\n",
        "\n",
        "sequence_length = 60\n",
        "sequences, targets = create_sequences(scaled, sequence_length)\n",
        "\n",
        "X = sequences[:, :-1, :]\n",
        "y = targets\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_train = X_train.to(device)\n",
        "y_train = y_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=512, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=512, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45961066",
      "metadata": {
        "id": "45961066"
      },
      "source": [
        "Модель Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ToVK3Hdj9qdX",
      "metadata": {
        "id": "ToVK3Hdj9qdX"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99df4380",
      "metadata": {
        "id": "99df4380"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_size, d_model, nhead, num_layers, output_size, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            norm_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.positional_encoding(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        out = x[:, -1, :]\n",
        "        out = self.fc_out(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5faf7cf",
      "metadata": {},
      "source": [
        "Функция подбора гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J771kqzfypFC",
      "metadata": {
        "id": "J771kqzfypFC"
      },
      "outputs": [],
      "source": [
        "def objective_transformer(trial):\n",
        "    d_model = trial.suggest_categorical(\"d_model\", [32, 64, 96, 128])\n",
        "    nhead_options = [h for h in [2, 4, 8] if d_model % h == 0]\n",
        "    if not nhead_options:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    nhead = trial.suggest_categorical(\"nhead\", nhead_options)\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
        "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "\n",
        "    model = TransformerModel(\n",
        "        input_size=4,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_layers=num_layers,\n",
        "        output_size=1,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(10):\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            val_loss += criterion(output, y_batch).item()\n",
        "\n",
        "    return val_loss / len(test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51e9f716",
      "metadata": {},
      "source": [
        "Подбор гиперпараметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1WUmaSOyp-G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1WUmaSOyp-G",
        "outputId": "f1d4b9ac-df5e-4a0c-a2ee-bafef563c0c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-06 00:22:48,809] A new study created in memory with name: no-name-bc99dc64-fd3e-41d8-94f3-f0aa9298af96\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "[I 2025-05-06 00:30:19,862] Trial 0 finished with value: 0.020540217868983746 and parameters: {'d_model': 32, 'nhead': 2, 'num_layers': 2, 'dropout': 0.27926562970379815, 'lr': 0.0013733978469872802}. Best is trial 0 with value: 0.020540217868983746.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n",
            "[I 2025-05-06 00:43:30,249] Trial 1 finished with value: 0.01540415920317173 and parameters: {'d_model': 64, 'nhead': 2, 'num_layers': 3, 'dropout': 0.41403648239411706, 'lr': 0.0025734413355351913}. Best is trial 1 with value: 0.01540415920317173.\n",
            "[I 2025-05-06 00:55:23,155] Trial 2 finished with value: 0.025845874100923538 and parameters: {'d_model': 128, 'nhead': 2, 'num_layers': 2, 'dropout': 0.26495241398703495, 'lr': 0.0024184972100475765}. Best is trial 1 with value: 0.01540415920317173.\n",
            "[I 2025-05-06 00:59:02,712] Trial 3 finished with value: 0.007231633644551039 and parameters: {'d_model': 32, 'nhead': 4, 'num_layers': 1, 'dropout': 0.21907156522363624, 'lr': 0.006444390952546524}. Best is trial 3 with value: 0.007231633644551039.\n",
            "[I 2025-05-06 01:21:28,759] Trial 4 finished with value: 0.03138470929116011 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 4, 'dropout': 0.2507815650238988, 'lr': 0.0013026610466484938}. Best is trial 3 with value: 0.007231633644551039.\n",
            "[I 2025-05-06 01:33:29,142] Trial 5 finished with value: 0.02258442062884569 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 3, 'dropout': 0.2526596253388096, 'lr': 0.00013483941217815978}. Best is trial 3 with value: 0.007231633644551039.\n",
            "[I 2025-05-06 01:36:56,517] Trial 6 finished with value: 0.0029818634502589703 and parameters: {'d_model': 32, 'nhead': 2, 'num_layers': 1, 'dropout': 0.30940187439168576, 'lr': 0.0036929115992776875}. Best is trial 6 with value: 0.0029818634502589703.\n",
            "[I 2025-05-06 02:00:47,255] Trial 7 finished with value: 0.01618780568242073 and parameters: {'d_model': 128, 'nhead': 2, 'num_layers': 4, 'dropout': 0.46479316197746856, 'lr': 0.0002953303251596585}. Best is trial 6 with value: 0.0029818634502589703.\n",
            "[I 2025-05-06 02:19:45,277] Trial 8 finished with value: 0.0017937502707354724 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 3, 'dropout': 0.4655244833163018, 'lr': 0.0011885199066746842}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 02:35:18,480] Trial 9 finished with value: 0.09056155383586884 and parameters: {'d_model': 96, 'nhead': 2, 'num_layers': 3, 'dropout': 0.27655583378802745, 'lr': 0.001948047482399989}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:00:35,567] Trial 10 finished with value: 0.012594060972332954 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 4, 'dropout': 0.11237878997656156, 'lr': 0.0005436341387419446}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:03:58,971] Trial 11 finished with value: 0.017126922495663166 and parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 1, 'dropout': 0.3854611713938932, 'lr': 0.00728614689654848}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:10:33,976] Trial 12 finished with value: 0.07714112848043442 and parameters: {'d_model': 32, 'nhead': 8, 'num_layers': 2, 'dropout': 0.37646436187821214, 'lr': 0.004064453413606439}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:16:10,990] Trial 13 finished with value: 0.007570939837023616 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 1, 'dropout': 0.4986621227143411, 'lr': 0.0006648548091064107}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:27:30,439] Trial 14 finished with value: 0.010069516487419605 and parameters: {'d_model': 128, 'nhead': 4, 'num_layers': 2, 'dropout': 0.33654961520473536, 'lr': 0.009829770474390686}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:36:35,354] Trial 15 finished with value: 0.04697803780436516 and parameters: {'d_model': 32, 'nhead': 2, 'num_layers': 3, 'dropout': 0.17141156244711844, 'lr': 0.004040066662304072}. Best is trial 8 with value: 0.0017937502707354724.\n",
            "[I 2025-05-06 03:40:46,328] Trial 16 finished with value: 0.0014596065739169717 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 1, 'dropout': 0.33377347840242144, 'lr': 0.0007303415873456501}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 03:49:24,572] Trial 17 finished with value: 0.002033062221016735 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 2, 'dropout': 0.44072055271217103, 'lr': 0.00033031522925106564}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:02:28,091] Trial 18 finished with value: 0.02012963779270649 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 3, 'dropout': 0.3478115615461264, 'lr': 0.0006154577584094182}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:21:07,840] Trial 19 finished with value: 0.037040406838059425 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 4, 'dropout': 0.49284608478960135, 'lr': 0.000932371130739216}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:26:02,437] Trial 20 finished with value: 0.007962419651448727 and parameters: {'d_model': 96, 'nhead': 8, 'num_layers': 1, 'dropout': 0.42346817333037046, 'lr': 0.0001075455583421523}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:34:17,319] Trial 21 finished with value: 0.010034318547695875 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 2, 'dropout': 0.4432782464505483, 'lr': 0.0003685742585172671}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:42:32,718] Trial 22 finished with value: 0.013813437893986702 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 2, 'dropout': 0.3934905212432067, 'lr': 0.00021442139515740407}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:55:42,265] Trial 23 finished with value: 0.008843028917908669 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 3, 'dropout': 0.4547392614008572, 'lr': 0.0003890664862537174}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 04:59:26,105] Trial 24 finished with value: 0.011758494656533003 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 1, 'dropout': 0.33858074607042377, 'lr': 0.00019629474657795987}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 05:11:28,980] Trial 25 finished with value: 0.006063372129574418 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 2, 'dropout': 0.4619424371313703, 'lr': 0.0008951297274351649}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 05:23:40,666] Trial 26 finished with value: 0.053720684722065926 and parameters: {'d_model': 64, 'nhead': 4, 'num_layers': 3, 'dropout': 0.3688024134387183, 'lr': 0.00046862164445903194}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 05:32:24,127] Trial 27 finished with value: 0.07388809695839882 and parameters: {'d_model': 64, 'nhead': 8, 'num_layers': 2, 'dropout': 0.4057601490072117, 'lr': 0.0013390664412827485}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 05:38:02,127] Trial 28 finished with value: 0.0020291379187256098 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 1, 'dropout': 0.4427749457597926, 'lr': 0.0002624409946356657}. Best is trial 16 with value: 0.0014596065739169717.\n",
            "[I 2025-05-06 05:43:32,103] Trial 29 finished with value: 0.00927409203723073 and parameters: {'d_model': 128, 'nhead': 8, 'num_layers': 1, 'dropout': 0.30648416248036053, 'lr': 0.0007890160548556729}. Best is trial 16 with value: 0.0014596065739169717.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'d_model': 64, 'nhead': 8, 'num_layers': 1, 'dropout': 0.33377347840242144, 'lr': 0.0007303415873456501}\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_transformer, n_trials=30)\n",
        "print(\"Best hyperparameters:\", study.best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1d2e9fd",
      "metadata": {
        "id": "c1d2e9fd"
      },
      "source": [
        "Параметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4bf6e5e",
      "metadata": {
        "id": "e4bf6e5e"
      },
      "outputs": [],
      "source": [
        "input_size = 4\n",
        "d_model = 64\n",
        "nhead = 8\n",
        "num_layers = 1\n",
        "output_size = 1\n",
        "num_epochs = 400\n",
        "dropout = 0.33377347840242144"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11eb0940",
      "metadata": {
        "id": "11eb0940"
      },
      "source": [
        "Инициализация модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0723d01",
      "metadata": {
        "id": "c0723d01"
      },
      "outputs": [],
      "source": [
        "model = TransformerModel(input_size=input_size, d_model=d_model, nhead=nhead, num_layers=num_layers, output_size=output_size, dropout=dropout)\n",
        "model = model.to(device)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a32aa700",
      "metadata": {
        "id": "a32aa700"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.00073034158734565018)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d710068",
      "metadata": {
        "id": "7d710068"
      },
      "source": [
        "Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o4eKmlnK__bI",
      "metadata": {
        "id": "o4eKmlnK__bI"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "best_model_state = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d483723",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d483723",
        "outputId": "0c633859-ab72-4858-e6ac-c5ab59a217f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/400], Loss: 0.0178, Val Loss: 0.0039\n",
            "Epoch [20/400], Loss: 0.0096, Val Loss: 0.0017\n",
            "Epoch [30/400], Loss: 0.0102, Val Loss: 0.0010\n",
            "Epoch [40/400], Loss: 0.0090, Val Loss: 0.0009\n",
            "Epoch [50/400], Loss: 0.0085, Val Loss: 0.0014\n",
            "Epoch [60/400], Loss: 0.0056, Val Loss: 0.0010\n",
            "Epoch [70/400], Loss: 0.0070, Val Loss: 0.0013\n",
            "Epoch [80/400], Loss: 0.0073, Val Loss: 0.0011\n",
            "Epoch [90/400], Loss: 0.0048, Val Loss: 0.0009\n",
            "Epoch [100/400], Loss: 0.0053, Val Loss: 0.0015\n",
            "Epoch [110/400], Loss: 0.0048, Val Loss: 0.0010\n",
            "Epoch [120/400], Loss: 0.0054, Val Loss: 0.0013\n",
            "Epoch [130/400], Loss: 0.0049, Val Loss: 0.0008\n",
            "Epoch [140/400], Loss: 0.0068, Val Loss: 0.0010\n",
            "Epoch [150/400], Loss: 0.0055, Val Loss: 0.0009\n",
            "Epoch [160/400], Loss: 0.0035, Val Loss: 0.0009\n",
            "Epoch [170/400], Loss: 0.0043, Val Loss: 0.0009\n",
            "Epoch [180/400], Loss: 0.0051, Val Loss: 0.0009\n",
            "Epoch [190/400], Loss: 0.0052, Val Loss: 0.0008\n",
            "Epoch [200/400], Loss: 0.0038, Val Loss: 0.0013\n",
            "Epoch [210/400], Loss: 0.0052, Val Loss: 0.0015\n",
            "Epoch [220/400], Loss: 0.0040, Val Loss: 0.0008\n",
            "Epoch [230/400], Loss: 0.0056, Val Loss: 0.0009\n",
            "Epoch [240/400], Loss: 0.0047, Val Loss: 0.0009\n",
            "Epoch [250/400], Loss: 0.0040, Val Loss: 0.0010\n",
            "Epoch [260/400], Loss: 0.0054, Val Loss: 0.0011\n",
            "Early stopping at epoch 266\n",
            "Training time: 7201.08 seconds\n"
          ]
        }
      ],
      "source": [
        "patience = 40\n",
        "best_val_loss = float('inf')\n",
        "early_stopping_counter = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_batch)\n",
        "        loss = criterion(output, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            output = model(X_batch)\n",
        "            val_loss += criterion(output, y_batch).item()\n",
        "    val_loss /= len(test_loader)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model_state = copy.deepcopy(model.state_dict())\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "        if early_stopping_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f4a864",
      "metadata": {},
      "outputs": [],
      "source": [
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eee12177",
      "metadata": {
        "id": "eee12177"
      },
      "source": [
        "Прогнозирование и возвращение оригинального масштаба"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e94ff3b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e94ff3b8",
        "outputId": "ed1de5a7-482b-44e4-b6a4-5bed338d64c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer RMSE: 30.07239980135927, MAE: 23.545352821763156, R²: 0.2751142928618131, Correlation: 0.543097185952459\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "y_test_original = y_test.cpu().numpy()\n",
        "y_pred_full = np.hstack([y_pred, np.zeros((y_pred.shape[0], 3))])\n",
        "y_test_full = np.hstack([y_test_original, np.zeros((y_test_original.shape[0], 3))])\n",
        "y_pred = scaler.inverse_transform(y_pred_full)[:, 0]\n",
        "y_test_original = scaler.inverse_transform(y_test_full)[:, 0]\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test_original, y_pred))\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_original, y_pred)\n",
        "correlation = np.corrcoef(y_test_original.flatten(), y_pred.flatten())[0, 1]\n",
        "\n",
        "print(f\"Transformer RMSE: {rmse}, MAE: {mae}, R²: {r2}, Correlation: {correlation}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
